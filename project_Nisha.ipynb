{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8aa0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e090174",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the test data \n",
    "\n",
    "#Load the test data\n",
    "test_data = pd.read_csv(\"C:/Users/HP/Downloads/CERTIFICATION/archive/Google_Stock_Price_Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "031ad3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date column to datetime format\n",
    "test_data['Date'] = pd.to_datetime(test_data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0311a2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by Date (if not already sorted)\n",
    "test_data = test_data.sort_values('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace23be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features (you may adjust this based on your requirements)\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "test_data = test_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cea296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "test_data_scaled = scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c80b3618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "def create_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequence = data[i : (i + sequence_length)]\n",
    "        sequences.append(sequence)\n",
    "    return sequences\n",
    "\n",
    "sequence_length = 10  # Adjust as needed\n",
    "test_sequences = create_sequences(test_data_scaled, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92bf7f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "test_sequences = np.array(test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f53cede8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sequences into features (X) and target (y)\n",
    "X_test = test_sequences[:, :-1]\n",
    "y_test = test_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95495896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input data to be 3D (samples, timesteps, features)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad5bb5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now X_test and y_test can be used to evaluate the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d59df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4683cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"C:/Users/HP/Downloads/CERTIFICATION/archive/Google_Stock_Price_Train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdf818d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_17116\\4210372300.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'])\n"
     ]
    }
   ],
   "source": [
    "# Convert the date column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "559704d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date column back to a string with a consistent format (e.g., YYYY-MM-DD)\n",
    "df['Date'] = df['Date'].dt.strftime('%m-%d-%Y')\n",
    "\n",
    "# Save the DataFrame back to a CSV file\n",
    "df.to_csv(\"updated_file.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e872b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your training data\n",
    "train_data = pd.read_csv(\"C:/Users/HP/Downloads/CERTIFICATION/archive/Google_Stock_Price_Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2d7c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Date column to datetime format\n",
    "train_data['Date'] = pd.to_datetime(train_data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b8f604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by Date (if not already sorted)\n",
    "train_data = train_data.sort_values('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebad0fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features\n",
    "features = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
    "train_data = train_data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65f01a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7049cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "def create_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        sequence = data[i : (i + sequence_length)]\n",
    "        sequences.append(sequence)\n",
    "    return sequences\n",
    "\n",
    "sequence_length = 10  # Adjust as needed\n",
    "train_sequences = create_sequences(train_data_scaled, sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18c06a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array\n",
    "train_sequences = np.array(train_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "260da8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split sequences into features (X) and target (y)\n",
    "X_train = train_sequences[:, :-1]\n",
    "y_train = train_sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3f98beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input data to be 3D (samples, timesteps, features)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], len(features))\n",
    "\n",
    "# Now X_train and y_train can be used to train the LSTM model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c14877d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Flatten\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "75d59bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(LSTM(units=50, return_sequences=False))  # Ensure return_sequences=False\n",
    "model.add(Flatten())  # Add a Flatten layer to convert output to 2D\n",
    "model.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0eca62f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd7b9b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3304\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2642\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2049\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1531\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1098\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0770\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0573\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0531\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0635\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1b453fe5950>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28d1aeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c8ceef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape predictions array to match the shape of y_test_actual\n",
    "predictions = predictions.reshape(-1, len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e233ee8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that both arrays have the same shape and number of samples\n",
    "min_samples = min(len(predictions), len(y_test_actual))\n",
    "predictions = predictions[:min_samples]\n",
    "y_test_actual = y_test_actual[:min_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87de1726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 573875443329.2654\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test_actual, predictions)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc777463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
